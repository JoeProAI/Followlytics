# ‚ö° Grok-2 Setup Guide

## Why Grok-2?

Grok-2 is X's native AI model and perfect for X/Twitter analysis:
- **Faster**: Optimized for X-related content understanding
- **Cheaper**: 20% cost savings vs GPT-4o ($2/M vs $2.50/M input tokens)
- **Native**: Built by X team, understands X context better
- **Latest**: Using `grok-2-1212` (December 2024 release)

## üöÄ Quick Setup

### 1. Get Your xAI API Key

1. Go to https://console.x.ai/
2. Sign in with your X account
3. Navigate to "API Keys"
4. Click "Create API Key"
5. Copy your key (starts with `xai-...`)

### 2. Add to Vercel Environment Variables

```bash
# In Vercel Dashboard ‚Üí Settings ‚Üí Environment Variables
XAI_API_KEY=xai-your-key-here
```

### 3. Redeploy

After adding the key, trigger a new deployment:
- Commit any small change to main branch, or
- Click "Redeploy" in Vercel dashboard

## ‚úÖ Verification

The system will automatically use Grok-2 when `XAI_API_KEY` is set.

**Check logs after analysis:**
```
[AI Analysis] Using grok-2-1212 for analysis
[AI Analysis] grok-2-1212 Cost: $0.0123 (1234 input + 5678 output tokens)
```

**Check UI:**
- Analysis results show badge: `‚ö° Grok`
- Model name displays: `grok-2-1212`

## üîÑ Fallback to OpenAI

If `XAI_API_KEY` is not set, system automatically uses GPT-4o:
```
[AI Analysis] Using gpt-4o for analysis
```

This means **zero downtime** if you want to switch back or test both.

## üí∞ Cost Comparison

### Example: Analyzing 50 followers

**Input:** ~3,000 tokens (follower data + prompt)
**Output:** ~2,000 tokens (detailed analysis JSON)

| Model | Input Cost | Output Cost | Total | Savings |
|-------|-----------|-------------|-------|---------|
| Grok-2 | $0.006 | $0.020 | **$0.026** | **-20%** |
| GPT-4o | $0.0075 | $0.020 | $0.0275 | baseline |

**At scale (1,000 analyses/month):**
- Grok-2: $26/month
- GPT-4o: $27.50/month
- **Savings: $1.50/month** (not huge but why not!)

## üéØ Best Practices

1. **Use Grok-2 for most AI analysis** - It's optimized for X content
2. **Keep OpenAI for specific tasks** - If you need GPT-specific features
3. **Monitor costs** - Check Firestore `ai_usage` stats for both providers
4. **Test both** - Compare quality on your specific use cases

## üîß Advanced: Switching Models Programmatically

The system supports both providers. To use specific provider:

```typescript
// In your API route
const useGrok = !!process.env.XAI_API_KEY
const modelName = useGrok ? 'grok-2-1212' : 'gpt-4o'
```

## üìä Model Specifications

### Grok-2-1212
- **Context Window**: 128K tokens
- **Training Data**: Up to Oct 2024 (more recent than GPT-4o)
- **Specialties**: X/Twitter content, real-time events, technical topics
- **Response Format**: JSON object support ‚úÖ
- **Speed**: ~2-3 seconds for 50 follower analysis

### GPT-4o (Fallback)
- **Context Window**: 128K tokens
- **Training Data**: Up to April 2024
- **Specialties**: General knowledge, creative writing
- **Response Format**: JSON object support ‚úÖ
- **Speed**: ~3-4 seconds for 50 follower analysis

## üÜò Troubleshooting

### Error: "XAI_API_KEY not set"
- Add key to Vercel environment variables
- Redeploy application
- System will auto-fallback to GPT-4o in meantime

### Error: "Invalid API key"
- Check key starts with `xai-`
- Verify key is active in X.AI console
- Regenerate key if needed

### Analysis slower than expected?
- Grok-2 should be faster than GPT-4o
- Check network latency to X.AI API
- Consider regional deployment closer to X.AI servers

### Want to force OpenAI?
- Temporarily remove `XAI_API_KEY` from Vercel
- System automatically uses GPT-4o
- Can switch back anytime

## üéâ What You Get

‚úÖ **20% cost savings** on AI analysis
‚úÖ **Faster analysis** (native X understanding)
‚úÖ **Automatic fallback** to GPT-4o if needed
‚úÖ **Zero code changes** required after setup
‚úÖ **Better X context** understanding
‚úÖ **Latest training data** (Oct 2024 vs Apr 2024)

## üìù Notes

- Both models produce identical JSON structure
- Analysis quality is comparable (test for your use case)
- Cost tracking works for both providers
- UI shows which model was used per analysis
- Can run some analyses on Grok, others on GPT-4o simultaneously
